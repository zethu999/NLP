{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d2c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260d15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34947b63",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4194413b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have three visions for India.',\n",
       " 'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.',\n",
       " 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\n               the French, the Dutch, all of them came and looted us, took over what was ours.',\n",
       " 'Yet we have not done this to any other nation.',\n",
       " 'We have not conquered anyone.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(para)\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16a957",
   "metadata": {},
   "source": [
    "- Removeing special cahractes, numbers, spaces and lowering the text, applying lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e769619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india',\n",
       " 'year history people world come invaded u captured land conquered mind',\n",
       " 'alexander onwards greek turk mogul portuguese british french dutch came looted u took',\n",
       " 'yet done nation',\n",
       " 'conquered anyone']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stoplist   = stopwords.words('english')\n",
    "cleaned_sentences_1 = []\n",
    "\n",
    "for i in range(len(sentences)) :\n",
    "    new_se = re.sub('[^a-zA-Z]',' ', sentences[i])\n",
    "    new_se = new_se.lower()\n",
    "    words  = nltk.word_tokenize(new_se)\n",
    "    words  = [lemmatizer.lemmatize(word) for word in words if word not in stoplist]\n",
    "    lemma  = ' '.join(words)\n",
    "    cleaned_sentences_1.append(lemma)\n",
    "    \n",
    "cleaned_sentences_1[:5]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e882e1",
   "metadata": {},
   "source": [
    "## Applying Bag of words, TF-IDF, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d2b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words, TF-IDF\n",
    "bow   = CountVectorizer()\n",
    "tfidf = TfidfVectorizer ()\n",
    "\n",
    "# Note - CountVectorizer(), TfidfVectorizer () takes sentences as input, finds no.of unique word (word frequency) and does operations\n",
    "#  Word2Vec() takes words as input and does the operation\n",
    "\n",
    "bow_vec   = bow.fit_transform(cleaned_sentences_1).toarray()\n",
    "tfidf_vec = tfidf.fit_transform(cleaned_sentences_1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90de271f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00220d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 114)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb507a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.54830459, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.63144608, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.54830459, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db74fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['three', 'vision', 'india'], ['year', 'history', 'people', 'world', 'come', 'invaded', 'u', 'captured', 'land', 'conquered', 'mind'], ['alexander', 'onwards', 'greek', 'turk', 'mogul', 'portuguese', 'british', 'french', 'dutch', 'came', 'looted', 'u', 'took'], ['yet', 'done', 'nation'], ['conquered', 'anyone']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nation',\n",
       " 'vision',\n",
       " 'india',\n",
       " 'respect',\n",
       " 'world',\n",
       " 'u',\n",
       " 'must',\n",
       " 'self',\n",
       " 'see',\n",
       " 'freedom']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences_2=[]\n",
    "\n",
    "for i in range(len(cleaned_sentences_1)):\n",
    "    temp_words = nltk.word_tokenize(cleaned_sentences_1[i])\n",
    "    cleaned_sentences_2.append(temp_words)\n",
    "    \n",
    "print(cleaned_sentences_2[:5])\n",
    "\n",
    "w2v   = Word2Vec(cleaned_sentences_2, min_count=1)\n",
    "words = list(w2v.wv.index_to_key)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e730bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3404522e-04,  2.4315513e-04,  5.1022521e-03,  9.0043079e-03,\n",
       "       -9.3029449e-03, -7.1323938e-03,  6.4657833e-03,  8.9799659e-03,\n",
       "       -5.0157560e-03, -3.7709095e-03,  7.3818588e-03, -1.5381071e-03,\n",
       "       -4.5357523e-03,  6.5596523e-03, -4.8605907e-03, -1.8181183e-03,\n",
       "        2.8752733e-03,  9.8503463e-04, -8.2882931e-03, -9.4587374e-03,\n",
       "        7.3102992e-03,  5.0775819e-03,  6.7513445e-03,  7.6609588e-04,\n",
       "        6.3488875e-03, -3.4090311e-03, -9.4173569e-04,  5.7641505e-03,\n",
       "       -7.5246505e-03, -3.9382037e-03, -7.5096413e-03, -9.2691829e-04,\n",
       "        9.5409499e-03, -7.3288167e-03, -2.3439366e-03, -1.9325595e-03,\n",
       "        8.0786105e-03, -5.9313430e-03,  5.4611111e-05, -4.7642463e-03,\n",
       "       -9.5990840e-03,  5.0010909e-03, -8.7572588e-03, -4.3946863e-03,\n",
       "       -2.6966669e-05, -2.9618997e-04, -7.6665664e-03,  9.6222619e-03,\n",
       "        4.9853469e-03,  9.2343790e-03, -8.1525091e-03,  4.4994978e-03,\n",
       "       -4.1287486e-03,  8.1654469e-04,  8.4964093e-03, -4.4622864e-03,\n",
       "        4.5140046e-03, -6.7832842e-03, -3.5546394e-03,  9.4003538e-03,\n",
       "       -1.5688424e-03,  3.2254323e-04, -4.1379551e-03, -7.6871994e-03,\n",
       "       -1.5074293e-03,  2.4645918e-03, -8.9020462e-04,  5.5347458e-03,\n",
       "       -2.7505932e-03,  2.2586584e-03,  5.4554241e-03,  8.3508361e-03,\n",
       "       -1.4541942e-03, -9.2068883e-03,  4.3870038e-03,  5.7629799e-04,\n",
       "        7.4377880e-03, -8.0967019e-04, -2.6337218e-03, -8.7572942e-03,\n",
       "       -8.4700569e-04,  2.8283789e-03,  5.3845202e-03,  7.0514707e-03,\n",
       "       -5.7039326e-03,  1.8542908e-03,  6.0950434e-03, -4.7955438e-03,\n",
       "       -3.0981742e-03,  6.8065263e-03,  1.6401230e-03,  1.9644636e-04,\n",
       "        3.4782651e-03,  2.2003644e-04,  9.6241720e-03,  5.0595044e-03,\n",
       "       -8.9161210e-03, -7.0406622e-03,  9.1273128e-04,  6.3826968e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv['nation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fd4b14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('independence', 0.290050208568573),\n",
       " ('growth', 0.22967712581157684),\n",
       " ('first', 0.21886560320854187),\n",
       " ('freedom', 0.21663855016231537),\n",
       " ('prakash', 0.20596864819526672),\n",
       " ('great', 0.195966899394989),\n",
       " ('four', 0.17263871431350708),\n",
       " ('dhawan', 0.16913852095603943),\n",
       " ('grabbed', 0.15185554325580597),\n",
       " ('brahm', 0.14339347183704376)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484fb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
